{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learner/Facilitator Guide - Advanced Keras Training - 30 Jul 2021.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "oD3qK9B4liVT",
        "jEpIw2V0lmGF",
        "TO3WCmo2nB-Q",
        "3H1vHLHUmUId",
        "vNCS7L2amtYn",
        "av71E0Qcnwon",
        "lkEPDE4CrSsf",
        "D6mpaNGixeDu",
        "YRck3uIwyeLo",
        "6naCWJHxygNk",
        "u4eKE0nEyxfk",
        "kMaVg1zTKCIG",
        "1sH7Cj5WKqoI",
        "QrlPLfRA65Td",
        "_JS9mnQOAyID",
        "njdRT2vKMXjl",
        "G_aEYm4PVptX",
        "AliO7-3ZVY0R",
        "6tZ-97-pcFIW",
        "dm-q7PEUcqbM",
        "RTcnxwuMdWST",
        "5K0jWGjHQCk4",
        "FhDR8jvnS1Fl",
        "Xt8tuJzrOCUK"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaZZDVcrO4gi"
      },
      "source": [
        "# Learner/Facilitator Guide for Advanced Keras Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr7i2L08IIp5"
      },
      "source": [
        "# Topic 1 Image Recognition with CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyEOuO2oByJX"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"Version: \", tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GoMUKLolzgg"
      },
      "source": [
        "## Image Classification Demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD3qK9B4liVT"
      },
      "source": [
        "### Step 1: Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GVgi54-2gk2"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEpIw2V0lmGF"
      },
      "source": [
        "#### ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtOhb7kR3AC4"
      },
      "source": [
        "batch_size = 100\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='categorical')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO3WCmo2nB-Q"
      },
      "source": [
        "#### Visualize the raw images "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSpOtG-O3P-k"
      },
      "source": [
        "images,labels = next(train_data_gen)\n",
        "\n",
        "def plotImages(images, labels):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, label, ax in zip( images, labels, axes):\n",
        "        ax.imshow(img)\n",
        "        label = np.argmax(label)\n",
        "        label = 'cat' if label == 0 else 'dog' \n",
        "        print(label)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plotImages(images[:5],labels[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H1vHLHUmUId"
      },
      "source": [
        "### Step 2: Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7r_aTsV3TMV"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD3LNOqJjfZ-"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNCS7L2amtYn"
      },
      "source": [
        "### Step 3: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG2URME73ePz"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "epochs = 15\n",
        "history = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av71E0Qcnwon"
      },
      "source": [
        "### Step 4: Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY2A6qRw3hee"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC5jis8VvsEv"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_path = '/content/test_dog.jpg'\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "img_tensor = image.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor /= 255.\n",
        "\n",
        "preds = model.predict(img_tensor)\n",
        "output = np.argmax(preds)\n",
        "label = 'cat' if output == 0 else 'dog'\n",
        "\n",
        "plt.imshow(img_tensor[0])\n",
        "plt.show()\n",
        "print(preds)\n",
        "print('The model prediction is ',label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EDpYogDg_Ow"
      },
      "source": [
        "## Activity: Image Classification with CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dmgdj_ald5B"
      },
      "source": [
        "### Step 1: Import the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuKgJdsOgtmz"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pUd6sBWhSHV"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "PATH = '/content/drive/MyDrive/dataset/hymenoptera_data'\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sLD9Dn9g0co"
      },
      "source": [
        "batch_size = 20\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='categorical')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEJqoddsiGtI"
      },
      "source": [
        "sample_training_images, _ = next(train_data_gen)\n",
        "\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plotImages(sample_training_images[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHQg8MW5lhqF"
      },
      "source": [
        "### Step 2: Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wRLNCNgiOPp"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35EBNY4_lkfo"
      },
      "source": [
        "### Step 3: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6s4f0wmiWj5"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "epochs = 15\n",
        "history = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqEpUJk_lnbw"
      },
      "source": [
        "### Step 4: Evalaute the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcAl9UkUkVLd"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VmYdrI0kZ82"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_path = '/content/348291597_ee836fbb1a.jpg'\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "img_tensor = image.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor /= 255.\n",
        "\n",
        "preds = model.predict(img_tensor)\n",
        "output = np.argmax(preds)\n",
        "label = 'ant' if output == 0 else 'bee'\n",
        "\n",
        "plt.imshow(img_tensor[0])\n",
        "plt.show()\n",
        "print('The model prediction is ',label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgViJ2IO1ndb"
      },
      "source": [
        "# Topic 2 Methods to Solve Overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HZGzGWOGQhn"
      },
      "source": [
        "## Weight Regularizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7_b81kfggeV"
      },
      "source": [
        "#### Step 1: Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLqq53QBgj7k"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkxUjTfTgxLg"
      },
      "source": [
        "batch_size = 100\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='categorical')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkEPDE4CrSsf"
      },
      "source": [
        "#### Step 2: Define the Model with L2 Weight Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIe71UZ6Ex52"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', kernel_regularizer=regularizers.l2(0.001), activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    # Conv2D(128, 3, padding='same', kernel_regularizer=regularizers.l2(0.001), activation='relu'),\n",
        "    # MaxPooling2D(),\n",
        "    # Conv2D(128, 3, padding='same', kernel_regularizer=regularizers.l2(0.001), activation='relu'),\n",
        "    # MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD8_C41FhH_b"
      },
      "source": [
        "#### Step 3: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZju7TMsFURb"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nupi8w3-IZ6G"
      },
      "source": [
        "#### Step 4: Evalaute the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNeqV73JGoTI"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8p6qllO2YLR"
      },
      "source": [
        "#### Step 2: Define the Model with L1 Weight Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2-O3eX-H5SP"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l1(0.001), input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', kernel_regularizer=regularizers.l1(0.001), activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    # Conv2D(128, 3, padding='same', kernel_regularizer=regularizers.l1(0.001), activation='relu'),\n",
        "    # MaxPooling2D(),\n",
        "    # Conv2D(128, 3, padding='same', kernel_regularizer=regularizers.l1(0.001), activation='relu'),\n",
        "    # MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro95F9LEIhb9"
      },
      "source": [
        "#### Step 3: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86Hm9YwqH_LJ"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjjokHfAIj4W"
      },
      "source": [
        "#### Step 4: Evalaute the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STgaNNW7IL24"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV7O_gPPIJFx"
      },
      "source": [
        "## Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWaQiuA-Lffs"
      },
      "source": [
        "#### Step 2: Define the Model with Dropout Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkPvPWENLwqa"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    # Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    # MaxPooling2D(),\n",
        "    # Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    # MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JR0TiHXIpBY"
      },
      "source": [
        "#### Step 3: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJsEedg5MBr8"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUBw2mfOIrYq"
      },
      "source": [
        "#### Step 4: Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yrp6D1LuMD7Q"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWgPlYfVILzT"
      },
      "source": [
        "## Data Augumenation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6mpaNGixeDu"
      },
      "source": [
        "#### Step 1: Load the Data with Data Augumentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkyUlE-g4KN6"
      },
      "source": [
        "image_gen_train = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=45,\n",
        "                    width_shift_range=.15,\n",
        "                    height_shift_range=.15,\n",
        "                    horizontal_flip=True,\n",
        "                    zoom_range=0.5\n",
        "                    )\n",
        "image_gen_val = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='categorical')\n",
        "\n",
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
        "                                                 directory=validation_dir,\n",
        "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                 class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMtG5LNYOMO-"
      },
      "source": [
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRck3uIwyeLo"
      },
      "source": [
        "#### Step 2: Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QU9CT1u4WYH"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    # Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    # MaxPooling2D(),\n",
        "    # Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    # MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6naCWJHxygNk"
      },
      "source": [
        "#### Step 3: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWN9-NfR4Z5y"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4eKE0nEyxfk"
      },
      "source": [
        "#### Step 4: Evalaute the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTVpfC2X4erj"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMaVg1zTKCIG"
      },
      "source": [
        "## Activity: Solve Overfitting Issue\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2raz9G07eX7"
      },
      "source": [
        "### Step 1: Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIw08yAA7f5J"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrV5JzSk78nB"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "PATH = '/content/drive/MyDrive/dataset/hymenoptera_data'\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPhfDE1l8ENh"
      },
      "source": [
        "batch_size = 20\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "image_gen_train = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=45,\n",
        "                    width_shift_range=.15,\n",
        "                    height_shift_range=.15,\n",
        "                    horizontal_flip=True,\n",
        "                    zoom_range=0.5\n",
        "                    )\n",
        "image_gen_val = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='categorical')\n",
        "\n",
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
        "                                                 directory=validation_dir,\n",
        "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                 class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06kkxusg7dAP"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqDXc56I7jpY"
      },
      "source": [
        "### Step 2: Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB2-2ZnP8T9Z"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrgZi16h7t2e"
      },
      "source": [
        "### Step 3: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn9Lctpx8rQ8"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_augmentation = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaCjOF6Q7wwQ"
      },
      "source": [
        "### Step 4: Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nOtnEl5-0Y0"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8M-eZxlU1Ql"
      },
      "source": [
        "# Topic 3 Functional Keras API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjzGIe8RcUDU"
      },
      "source": [
        "## Layer as Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkQ7H5seBXD_"
      },
      "source": [
        "#### Step 1: Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_H2NX6Lb0mC"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1My_b-RucG3x"
      },
      "source": [
        "batch_size = 20\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='categorical')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LG_dDpJMBlll"
      },
      "source": [
        "#### Step 2: Define the Model with Functional API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhDM8qHIcQWA"
      },
      "source": [
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# model = Sequential([\n",
        "#     Conv2D(32, 3, padding='same', activation='relu', input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "#     MaxPooling2D(),\n",
        "#     Conv2D(64, 3, padding='same', activation='relu'),\n",
        "#     MaxPooling2D(),\n",
        "#     Conv2D(128, 3, padding='same', activation='relu'),\n",
        "#     MaxPooling2D(),\n",
        "#     Conv2D(128, 3, padding='same', activation='relu'),\n",
        "#     MaxPooling2D(),\n",
        "#     Flatten(),\n",
        "#     Dense(512, activation='relu'),\n",
        "#     Dense(2, activation='softmax')\n",
        "# ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njf-bL8HcfWM"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "inputs = keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH,3))\n",
        "x = Conv2D(32, 3, padding='same', activation='relu')(inputs)\n",
        "x = MaxPooling2D()(x)\n",
        "x = Conv2D(64, 3, padding='same', activation='relu')(x)\n",
        "x = MaxPooling2D()(x)\n",
        "x = Conv2D(128, 3, padding='same', activation='relu')(x)\n",
        "x = MaxPooling2D()(x)\n",
        "x = Conv2D(128, 3, padding='same', activation='relu')(x)\n",
        "x = MaxPooling2D()(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "outputs = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6t4zUIBBsUH"
      },
      "source": [
        "#### Step 3: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjiVw0bmeDyY"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk8TPI8ZBwE7"
      },
      "source": [
        "#### Step 4: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrwT5BTYeuRf"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sH7Cj5WKqoI"
      },
      "source": [
        "### Activity: Functional API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_2EuMEOERaW"
      },
      "source": [
        "#### Step 1: Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIikWWgIgMKg"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7yyGamQgZot"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "PATH = '/content/drive/MyDrive/dataset/hymenoptera_data'\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SpQxJ73ggKv"
      },
      "source": [
        "batch_size = 20\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='categorical')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_x6RmGWEWUz"
      },
      "source": [
        "#### Step 2: Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-VDJbNbgwvZ"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "inputs = keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH,3))\n",
        "x = Conv2D(32, 3, padding='same', activation='relu')(inputs)\n",
        "x = MaxPooling2D()(x)\n",
        "x = Conv2D(64, 3, padding='same', activation='relu')(x)\n",
        "x = MaxPooling2D()(x)\n",
        "x = Conv2D(128, 3, padding='same', activation='relu')(x)\n",
        "x = MaxPooling2D()(x)\n",
        "x = Conv2D(128, 3, padding='same', activation='relu')(x)\n",
        "x = MaxPooling2D()(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "outputs = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSQ5sXbsEY91"
      },
      "source": [
        "#### Step 3: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT4u4jVNhD-a"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9THMAsXREbtj"
      },
      "source": [
        "#### Step 4: Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wGHJ3FMhPWR"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We_i4QsMJhCG"
      },
      "source": [
        "## Feature Map Visualizaton\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igKP2xKUKOor"
      },
      "source": [
        "#### Step 1: Load the Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC8Ncg4XuRN9"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_path = '/content/dog.2456.jpg'\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "img_tensor = image.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor /= 255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPgo9Uj2mn25"
      },
      "source": [
        "for i, layer in enumerate(model.layers):\n",
        "    print(i,layer.name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maeXjywYKw11"
      },
      "source": [
        "#### Step 2: Visualize Feature Map for Layer 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSET3--n-JSn"
      },
      "source": [
        "layer_outputs = [layer.output for layer in model.layers[0:1]]\n",
        "activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
        "activation = activation_model.predict(img_tensor)\n",
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "for i in range(16):\n",
        "    plt.subplot(4,4,i+1)\n",
        "    plt.imshow(activation[0, :, :, i])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg2PwjuRKhMb"
      },
      "source": [
        "#### Step 2: Visualize Feature Map for Layer 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YF-rx5uwFNz"
      },
      "source": [
        "layer_outputs = [layer.output for layer in model.layers[1:2]]\n",
        "activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
        "activation = activation_model.predict(img_tensor)\n",
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "for i in range(16):\n",
        "    plt.subplot(4,4,i+1)\n",
        "    plt.imshow(activation[0, :, :, i])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJHTJpviLzPX"
      },
      "source": [
        "#### Step 2: Visualize Feature Map for Layer 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnyQ0qURnVym"
      },
      "source": [
        "layer_outputs = [layer.output for layer in model.layers[2:3]]\n",
        "activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
        "activation = activation_model.predict(img_tensor)\n",
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "for i in range(16):\n",
        "    plt.subplot(4,4,i+1)\n",
        "    plt.imshow(activation[0, :, :, i])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3f_mhKwL0-Q"
      },
      "source": [
        "#### Step 2: Visualize Feature Map for Layer 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys7TIUoaLCqW"
      },
      "source": [
        "layer_outputs = [layer.output for layer in model.layers[3:4]]\n",
        "activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
        "activation = activation_model.predict(img_tensor)\n",
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "for i in range(16):\n",
        "    plt.subplot(4,4,i+1)\n",
        "    plt.imshow(activation[0, :, :, i])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtPpxGzPstu0"
      },
      "source": [
        "### Activity: Feature Map Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2uY2WJtKSRU"
      },
      "source": [
        "#### Step 1: Load the Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLN00vK_J_FK"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ng8mYygKCAx"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "PATH = '/content/drive/MyDrive/dataset/hymenoptera_data'\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjAczVTGKFn0"
      },
      "source": [
        "batch_size = 20\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='categorical')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeP6VOk_LM3p"
      },
      "source": [
        "#### Step 2: Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bBuTP-ZKImD"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "inputs = keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH,3))\n",
        "x = Conv2D(32, 3, padding='same', activation='relu')(inputs)\n",
        "x = MaxPooling2D()(x)\n",
        "x = Conv2D(64, 3, padding='same', activation='relu')(x)\n",
        "x = MaxPooling2D()(x)\n",
        "x = Conv2D(128, 3, padding='same', activation='relu')(x)\n",
        "x = MaxPooling2D()(x)\n",
        "x = Conv2D(128, 3, padding='same', activation='relu')(x)\n",
        "x = MaxPooling2D()(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "outputs = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMNu-A-zLPxu"
      },
      "source": [
        "#### Step 3: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Btk12c5xKLyw"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SSSrTMFLS1j"
      },
      "source": [
        "#### Step 4: Visualize the Feature Maps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkj2LW13wPCy"
      },
      "source": [
        "for i, layer in enumerate(model.layers):\n",
        "    print(i,layer.name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI3AjEG8wi3x"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_path = '/content/348291597_ee836fbb1a.jpg'\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "img_tensor = image.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor /= 255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHuLYMC02C63"
      },
      "source": [
        "layer_outputs = [layer.output for layer in model.layers[0:1]]\n",
        "activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
        "activation = activation_model.predict(img_tensor)\n",
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "for i in range(16):\n",
        "    plt.subplot(4,4,i+1)\n",
        "    plt.imshow(activation[0, :, :, i])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgpKOgzyc3S3"
      },
      "source": [
        "layer_outputs = [layer.output for layer in model.layers[6:7]]\n",
        "activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
        "activation = activation_model.predict(img_tensor)\n",
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "for i in range(128):\n",
        "    plt.subplot(32,8,i+1)\n",
        "    plt.imshow(activation[0, :, :, i])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nbefACoDOxb"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    #MaxPooling2D(),\n",
        "    Conv2D(16, 3, padding='same', activation='relu'),\n",
        "    #MaxPooling2D(),\n",
        "    Conv2D(16, 3, padding='same', activation='relu'),\n",
        "    #MaxPooling2D(),\n",
        "    Conv2D(16, 3, padding='same', activation='relu'),\n",
        "    #MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxjSYaS-DiHC"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "epochs = 15\n",
        "history = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HeWq_7zY6oh"
      },
      "source": [
        "# Topic 4 Transfer Learning for Small Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVy4LTOaVTTV"
      },
      "source": [
        "## Test the Pre-trained Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkdwKtNbx9WT"
      },
      "source": [
        "### Renset Pre-trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vczf7wydxzf1"
      },
      "source": [
        "# Resnet Pre-trained Model\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "\n",
        "model = ResNet50(weights='imagenet')\n",
        "\n",
        "img_path = '/content/348291597_ee836fbb1a.jpg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = model.predict(x)\n",
        "print('Predicted:', decode_predictions(preds, top=3)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCwzkI5JyDYP"
      },
      "source": [
        "### Mobilenet Pre-trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1Jwg2kZx433"
      },
      "source": [
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "\n",
        "model = MobileNetV2(weights='imagenet')\n",
        "\n",
        "img_path = '/content/guess3.jpg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = model.predict(x)\n",
        "print('Predicted:', decode_predictions(preds, top=3)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_aEYm4PVptX"
      },
      "source": [
        "## Feature Extraction & Fine Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRvTRHqgVz9a"
      },
      "source": [
        "### Step 1: Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEuOIRD0VnTc"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_jEgw_HVwGf"
      },
      "source": [
        "batch_size = 20\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='categorical')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPipA2mPWACH"
      },
      "source": [
        "### Step 2: Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oC6b5TlezSh4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow. keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5oFy8mPzroV"
      },
      "source": [
        "base_model=MobileNet(weights='imagenet',include_top=False, input_shape=(150, 150, 3)) \n",
        "\n",
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x) \n",
        "x=Dense(512,activation='relu')(x) \n",
        "preds=Dense(2,activation='softmax')(x) \n",
        "\n",
        "model=Model(inputs=base_model.input,outputs=preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_SuYmC4k6dI"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5Uf1n7ul76f"
      },
      "source": [
        "#### Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eMSbERplvws"
      },
      "source": [
        "base_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvxkgU8Jl_5T"
      },
      "source": [
        "#### Fine Tunning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0G65Lqr0M1_"
      },
      "source": [
        "# for layer in model.layers[:20]:\n",
        "#     layer.trainable=False\n",
        "# for layer in model.layers[20:]:\n",
        "#     layer.trainable=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coVbrIe9WXzW"
      },
      "source": [
        "### Step 3: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGOyEsScWd_y"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_augmentation = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ5Bf_mtWjfR"
      },
      "source": [
        "### Step 4: Evalaute the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JAVJ6-Ym6wk"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AliO7-3ZVY0R"
      },
      "source": [
        "### Step 5: Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f_HxRBW0aGd"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_path = 'test_cat.jpg'\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "img_tensor = image.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor /= 255.\n",
        "\n",
        "preds = model.predict(img_tensor)\n",
        "output = np.argmax(preds)\n",
        "label = 'cat' if output == 0 else 'dog'\n",
        "\n",
        "plt.imshow(img_tensor[0])\n",
        "plt.show()\n",
        "print('The model prediction is ',label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz3J0aNwurpH"
      },
      "source": [
        "## Activity: Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFbS8PerYhV2"
      },
      "source": [
        "### Step 1: Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbzK7o6bvBKu"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMnmd1nQvFR1"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "PATH = '/content/drive/MyDrive/dataset/hymenoptera_data'\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gYSJX5NvMc2"
      },
      "source": [
        "batch_size = 20\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='categorical')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ8v1QCMYmJD"
      },
      "source": [
        "### Step 2: Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq6_PpsvvhcF"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow. keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4aDUH0kvoZI"
      },
      "source": [
        "base_model=MobileNet(weights='imagenet',include_top=False, input_shape=(150, 150, 3)) \n",
        "\n",
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x) \n",
        "x=Dense(512,activation='relu')(x) \n",
        "preds=Dense(2,activation='softmax')(x) \n",
        "\n",
        "model=Model(inputs=base_model.input,outputs=preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQQ00Y_cvsjr"
      },
      "source": [
        "base_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3SQA-DWY3_h"
      },
      "source": [
        "### Step 3: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp9rtyVNv3hh"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFB6L-JGZGNA"
      },
      "source": [
        "### Step 4: Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_jwxSBk2XaO"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuSEeNkkZTe9"
      },
      "source": [
        "### Step 5: Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw3kKZOuZQp5"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_path = '/content/348291597_ee836fbb1a.jpg'\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "img_tensor = image.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor /= 255.\n",
        "\n",
        "preds = model.predict(img_tensor)\n",
        "output = np.argmax(preds)\n",
        "label = 'cat' if output == 0 else 'dog'\n",
        "\n",
        "plt.imshow(img_tensor[0])\n",
        "plt.show()\n",
        "print('The model prediction is ',label)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}